{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='font-family:Georgia'> Objectives\n",
    "The purpose of this notebook is beginning of creating a baseline rule-model, which is to be a benchmark of the neural model developed in the later phase of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T11:12:10.284153Z",
     "start_time": "2022-04-15T11:12:06.860703Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from supportive_functions import rm_consecutive_spaces\n",
    "\n",
    "\n",
    "sns.set(\n",
    "    rc={\n",
    "        \"figure.figsize\": (14, 8.27),\n",
    "        \"axes.facecolor\": \"white\",\n",
    "        \"axes.grid\": True,\n",
    "        \"grid.color\": \".9\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T11:12:10.299775Z",
     "start_time": "2022-04-15T11:12:10.284153Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_files(dir_path: str, sep: str = \",\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read the files with timestamps from a given catalog.\n",
    "\n",
    "    Args:\n",
    "        dir_path: Path to the catalog with the files\n",
    "        sep: Separator used in pd.read_csv() function. Defaults to \",\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Data from all the files concatenated into one dataframe.\n",
    "    \"\"\"\n",
    "    files = os.listdir(dir_path)\n",
    "    data = pd.DataFrame(\n",
    "        [], columns=[\"index\", \"timestamp_start\", \"timestamp_stop\", \"word\"]\n",
    "    )\n",
    "    for file in tqdm(files):\n",
    "        f = open(os.path.join(dir_path, file), encoding=\"utf-8\", mode=\"r\")\n",
    "        name = file.split(\".\")[0]\n",
    "        df = pd.read_csv(f, header=None, sep=sep, encoding=\"utf-8\")\n",
    "        df[\"index\"] = name\n",
    "        if sep != \",\":\n",
    "            df[\"timestamp_start\"] = df.iloc[:, 0].str.split(\",\").str[0].str[1:]\n",
    "            df[\"timestamp_stop\"] = (\n",
    "                df.iloc[:, 0].str.split(\",\").str[1].str.split(\"\\)\").str[0]\n",
    "            )\n",
    "            df[\"word\"] = df.iloc[:, 0].str.split(\"\\)+\\s\").str[1]\n",
    "            df.drop([0], axis=1, inplace=True)\n",
    "            df.drop(df.tail(1).index, inplace=True)\n",
    "        else:\n",
    "            df[\"timestamp_start\"] = df.iloc[:, 0].str[1:]\n",
    "            df[\"timestamp_stop\"] = df.iloc[:, 1].str.split(\"\\)+\\s\").str[0]\n",
    "            df[\"word\"] = df.iloc[:, 1].str.split(\"\\)+\\s\").str[1]\n",
    "\n",
    "            df.drop([0, 1], axis=1, inplace=True)\n",
    "            df.drop(df.tail(1).index, inplace=True)\n",
    "        data = pd.concat([data, df])\n",
    "        f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T11:12:10.319957Z",
     "start_time": "2022-04-15T11:12:10.302100Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_pauses(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate new features describing pauses between two timestamps.\n",
    "\n",
    "    Args:\n",
    "        data: Dataframe with preprocessed timestamp data separated\n",
    "        into 'timestamp_start' and 'timestamp_stop' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Input dataframe with two new features added,\n",
    "        describing the pause between the word and after it.\n",
    "    \"\"\"\n",
    "    data.timestamp_start = data.timestamp_start.astype(int)\n",
    "    data.timestamp_stop = data.timestamp_stop.astype(int)\n",
    "    data_shifted = pd.concat(\n",
    "        [data, data.timestamp_start.shift(-1), data.timestamp_stop.shift()], axis=1\n",
    "    )\n",
    "    data_shifted.columns = [\n",
    "        \"index\",\n",
    "        \"timestamp_start\",\n",
    "        \"timestamp_stop\",\n",
    "        \"word\",\n",
    "        \"timestamp_start_lead\",\n",
    "        \"timestamp_stop_lag\",\n",
    "    ]\n",
    "    data_shifted[\"pause_before\"] = (\n",
    "        data_shifted.timestamp_start - data_shifted.timestamp_stop_lag\n",
    "    )\n",
    "    data_shifted[\"pause_after\"] = (\n",
    "        data_shifted.timestamp_start_lead - data_shifted.timestamp_stop\n",
    "    )\n",
    "    data_shifted.drop(\n",
    "        [\"timestamp_start_lead\", \"timestamp_stop_lag\"], axis=1, inplace=True\n",
    "    )\n",
    "    # to discuss\n",
    "    data_shifted.pause_before.fillna(data_shifted.timestamp_start, inplace=True)\n",
    "    data_shifted.pause_after.fillna(0, inplace=True)\n",
    "    data_shifted.reset_index(drop=True, inplace=True)\n",
    "    for i, row in data_shifted.iterrows():\n",
    "        if (i > 0) and (\n",
    "            data_shifted.loc[i, \"index\"] != data_shifted.loc[i - 1, \"index\"]\n",
    "        ):\n",
    "            data_shifted.loc[i, \"pause_before\"] = data_shifted.loc[i, \"timestamp_start\"]\n",
    "            data_shifted.loc[i - 1, \"pause_after\"] = 0\n",
    "\n",
    "    return data_shifted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='font-family:Georgia'> Data preparation & pauses calculation\n",
    "\n",
    "### <span style='font-family:Georgia'> Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 793/793 [00:24<00:00, 32.04it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 49.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_train = read_files(\"./data/forced-alignment/train\", sep=\"\\t\")\n",
    "\n",
    "data_train_calc = calculate_pauses(data_train).drop(\n",
    "    [\"timestamp_start\", \"timestamp_stop\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>pause_before</th>\n",
       "      <th>pause_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikinews178430</td>\n",
       "      <td>we</td>\n",
       "      <td>690.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wikinews178430</td>\n",
       "      <td>wrocławiu</td>\n",
       "      <td>90.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wikinews178430</td>\n",
       "      <td>walkę</td>\n",
       "      <td>300.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index       word  pause_before  pause_after\n",
       "0  wikinews178430         we         690.0         90.0\n",
       "1  wikinews178430  wrocławiu          90.0        300.0\n",
       "2  wikinews178430      walkę         300.0        210.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_calc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train symbols and noisy words\n",
    "# load list of symbols to replace\n",
    "symbols_to_replace_infile = open(\n",
    "    \"./data/out/eda/symbols_to_replace.txt\", \"r\", encoding=\"utf-8\"\n",
    ")\n",
    "symbols_to_replace = symbols_to_replace_infile.read().splitlines()\n",
    "# load list of noisy words, i.e. words with letters from outside the Polish alphabet\n",
    "noisy_words_infile = open(\"./data/out/eda/noisy_words.txt\", \"r\", encoding=\"utf-8\")\n",
    "noisy_words = noisy_words_infile.read().splitlines()\n",
    "# load list of letters from outside the Polish alphabet\n",
    "non_polish_letters_infile = open(\n",
    "    \"./data/out/eda/non_polish_letters.txt\", \"r\", encoding=\"utf-8\"\n",
    ")\n",
    "non_polish_letters = non_polish_letters_infile.read().splitlines()\n",
    "\n",
    "# merge noisy data into one list\n",
    "symbols_to_replace.extend(noisy_words)\n",
    "symbols_to_replace.extend(non_polish_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining data into whole records\n",
    "\n",
    "data_train_calc_joined = (\n",
    "    data_train_calc[[\"index\", \"word\"]]\n",
    "    .groupby([\"index\"])[\"word\"]\n",
    "    .agg(\" \".join)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symb in symbols_to_replace:\n",
    "    data_train_calc_joined[\"word\"] = data_train_calc_joined[\"word\"].apply(\n",
    "        lambda x: x.replace(symb, \"\")\n",
    "    )\n",
    "\n",
    "data_train_calc_joined[\"word\"] = data_train_calc_joined[\"word\"].apply(\n",
    "    rm_consecutive_spaces\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileId</th>\n",
       "      <th>FixedOutput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikinews178430</td>\n",
       "      <td>we wrocławiu walkę ze szkodnikiem rozpoczyna z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wikinews178747</td>\n",
       "      <td>do serii rozbojów doszło w środę wieczorem w l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wikinews178788</td>\n",
       "      <td>trzech 19 latków zatrzymała wczoraj lubelska p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikinews178804</td>\n",
       "      <td>drugie zwycięstwo w tegorocznym giro ditalia o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wikinews178814</td>\n",
       "      <td>kradzieże telefonów komórkowych to coraz częst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           FileId                                        FixedOutput\n",
       "0  wikinews178430  we wrocławiu walkę ze szkodnikiem rozpoczyna z...\n",
       "1  wikinews178747  do serii rozbojów doszło w środę wieczorem w l...\n",
       "2  wikinews178788  trzech 19 latków zatrzymała wczoraj lubelska p...\n",
       "3  wikinews178804  drugie zwycięstwo w tegorocznym giro ditalia o...\n",
       "4  wikinews178814  kradzieże telefonów komórkowych to coraz częst..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMPARISON - check whether base records in timestamps and tabular data are the same\n",
    "# reading preprocessed text data for comparison (without punctuation)\n",
    "data_train_clean = pd.read_csv('data/out/data_cleaning/train_with_ids_clean.csv')\n",
    "data_train_clean = data_train_clean.sort_values('FileId').reset_index(drop=True)\n",
    "data_train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileId</th>\n",
       "      <th>FixedOutput</th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikinews178430</td>\n",
       "      <td>we wrocławiu walkę ze szkodnikiem rozpoczyna z...</td>\n",
       "      <td>wikinews178430</td>\n",
       "      <td>we wrocławiu walkę ze szkodnikiem rozpoczyna z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wikinews178747</td>\n",
       "      <td>do serii rozbojów doszło w środę wieczorem w l...</td>\n",
       "      <td>wikinews178747</td>\n",
       "      <td>do serii rozbojów doszło w środę wieczorem w l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wikinews178788</td>\n",
       "      <td>trzech 19 latków zatrzymała wczoraj lubelska p...</td>\n",
       "      <td>wikinews178788</td>\n",
       "      <td>trzech 19 latków zatrzymała wczoraj lubelska p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikinews178804</td>\n",
       "      <td>drugie zwycięstwo w tegorocznym giro ditalia o...</td>\n",
       "      <td>wikinews178804</td>\n",
       "      <td>drugie zwycięstwo w tegorocznym giro ditalia o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wikinews178814</td>\n",
       "      <td>kradzieże telefonów komórkowych to coraz częst...</td>\n",
       "      <td>wikinews178814</td>\n",
       "      <td>kradzieże telefonów komórkowych to coraz częst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           FileId                                        FixedOutput  \\\n",
       "0  wikinews178430  we wrocławiu walkę ze szkodnikiem rozpoczyna z...   \n",
       "1  wikinews178747  do serii rozbojów doszło w środę wieczorem w l...   \n",
       "2  wikinews178788  trzech 19 latków zatrzymała wczoraj lubelska p...   \n",
       "3  wikinews178804  drugie zwycięstwo w tegorocznym giro ditalia o...   \n",
       "4  wikinews178814  kradzieże telefonów komórkowych to coraz częst...   \n",
       "\n",
       "            index                                               word  \n",
       "0  wikinews178430  we wrocławiu walkę ze szkodnikiem rozpoczyna z...  \n",
       "1  wikinews178747  do serii rozbojów doszło w środę wieczorem w l...  \n",
       "2  wikinews178788  trzech 19 latków zatrzymała wczoraj lubelska p...  \n",
       "3  wikinews178804  drugie zwycięstwo w tegorocznym giro ditalia o...  \n",
       "4  wikinews178814  kradzieże telefonów komórkowych to coraz częst...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging for comparison\n",
    "data_train_merged = data_train_clean.merge(\n",
    "    data_train_calc_joined, left_on=\"FileId\", right_on=\"index\"\n",
    ")\n",
    "data_train_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same records:  793\n",
      "Error records:  0\n"
     ]
    }
   ],
   "source": [
    "# fixing errors (mainly spaces at the end)\n",
    "data_train_merged[\"compare\"] = (\n",
    "    data_train_merged[\"FixedOutput\"] == data_train_merged[\"word\"]\n",
    ")\n",
    "data_train_merged.loc[\n",
    "    data_train_merged[\"compare\"] == False, \"word\"\n",
    "] = data_train_merged.loc[data_train_merged[\"compare\"] == False, \"word\"].str.strip()\n",
    "data_train_merged[\"compare\"] = (\n",
    "    data_train_merged[\"FixedOutput\"] == data_train_merged[\"word\"]\n",
    ")\n",
    "data_train_merged.loc[\n",
    "    data_train_merged[\"compare\"] == False, \"FixedOutput\"\n",
    "] = data_train_merged.loc[\n",
    "    data_train_merged[\"compare\"] == False, \"FixedOutput\"\n",
    "].str.strip()\n",
    "data_train_merged[\"compare\"] = (\n",
    "    data_train_merged[\"FixedOutput\"] == data_train_merged[\"word\"]\n",
    ")\n",
    "print(\"Same records: \", data_train_merged[\"compare\"].sum())\n",
    "print(\n",
    "    \"Error records: \", data_train_merged.shape[0] - data_train_merged[\"compare\"].sum()\n",
    ")\n",
    "data_train_merged.to_csv(\"temp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='font-family:Georgia'> Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = read_files(\"./data/forced-alignment/validation\", sep=\"\\t\")\n",
    "data_test_calc = calculate_pauses(data_test).drop(\n",
    "    [\"timestamp_start\", \"timestamp_stop\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>pause_before</th>\n",
       "      <th>pause_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikinews179014</td>\n",
       "      <td>w</td>\n",
       "      <td>390.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wikinews179014</td>\n",
       "      <td>gdańsku</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wikinews179014</td>\n",
       "      <td>zgodnie</td>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index     word  pause_before  pause_after\n",
       "0  wikinews179014        w         390.0         30.0\n",
       "1  wikinews179014  gdańsku          30.0         60.0\n",
       "2  wikinews179014  zgodnie          60.0         30.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_calc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test symbols and noisy words\n",
    "# load list of symbols to replace\n",
    "symbols_to_replace_infile_test = open(\n",
    "    \"./data/out/eda/symbols_to_replace.txt\", \"r\", encoding=\"utf-8\"\n",
    ")\n",
    "symbols_to_replace_test = symbols_to_replace_infile_test.read().splitlines()\n",
    "# load list of noisy words, i.e. words with letters from outside the Polish alphabet\n",
    "noisy_words_infile_test = open(\"./data/out/test/noisy_words.txt\", \"r\", encoding=\"utf-8\")\n",
    "noisy_words_test = noisy_words_infile_test.read().splitlines()\n",
    "# load list of letters from outside the Polish alphabet\n",
    "non_polish_letters_infile_test = open(\n",
    "    \"./data/out/test/non_polish_letters.txt\", \"r\", encoding=\"utf-8\"\n",
    ")\n",
    "non_polish_letters_test = non_polish_letters_infile_test.read().splitlines()\n",
    "\n",
    "# merge noisy data into one list\n",
    "noisy_words_test.extend(non_polish_letters_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\", '\"', ';', '%', '(', ')', '[', ']', '²', '€', '³', '+', '·']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols_to_replace_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_calc_joined = (\n",
    "    data_test_calc[[\"index\", \"word\"]]\n",
    "    .groupby([\"index\"])[\"word\"]\n",
    "    .agg(\" \".join)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symb in noisy_words_test:\n",
    "    data_test_calc_joined[\"word\"] = data_test_calc_joined[\"word\"].apply(\n",
    "        lambda x: x.replace(symb, \"\")\n",
    "    )\n",
    "\n",
    "data_test_calc_joined[\"word\"] = data_test_calc_joined[\"word\"].apply(\n",
    "    rm_consecutive_spaces\n",
    ")\n",
    "\n",
    "for symb in symbols_to_replace_test:\n",
    "    data_test_calc_joined[\"word\"] = data_test_calc_joined[\"word\"].apply(\n",
    "        lambda x: x.replace(symb, \"\")\n",
    "    )\n",
    "\n",
    "data_test_calc_joined[\"word\"] = data_test_calc_joined[\"word\"].apply(\n",
    "    rm_consecutive_spaces\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileId</th>\n",
       "      <th>ASROutput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikinews179014</td>\n",
       "      <td>w gdańsku zgodnie już z coroczną czerwcową tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wikinews179354</td>\n",
       "      <td>prezydent usa george bush powiedział że odnowa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wikinews179650</td>\n",
       "      <td>mamy najgorsze przedmieścia w europie nie woln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikinews179740</td>\n",
       "      <td>w sejmie trwała dziś debata nad sprawozdaniem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wikinews179784</td>\n",
       "      <td>aleksander łukaszenka który za 3 miesiące będz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           FileId                                          ASROutput\n",
       "0  wikinews179014  w gdańsku zgodnie już z coroczną czerwcową tra...\n",
       "1  wikinews179354  prezydent usa george bush powiedział że odnowa...\n",
       "2  wikinews179650  mamy najgorsze przedmieścia w europie nie woln...\n",
       "3  wikinews179740  w sejmie trwała dziś debata nad sprawozdaniem ...\n",
       "4  wikinews179784  aleksander łukaszenka który za 3 miesiące będz..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMPARISON - check whether base records in timestamps and tabular data are the same\n",
    "# reading preprocessed text data for comparison (without punctuation)\n",
    "data_test_clean = pd.read_csv('./data/out/data_cleaning/test_with_ids_clean.csv')\n",
    "data_test_clean = data_test_clean.sort_values('FileId').reset_index(drop=True)\n",
    "data_test_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikinews179014</td>\n",
       "      <td>w gdańsku zgodnie już z coroczną czerwcową tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wikinews179354</td>\n",
       "      <td>prezydent usa george bush powiedział że odnowa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wikinews179650</td>\n",
       "      <td>mamy najgorsze przedmieścia w europie nie woln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikinews179740</td>\n",
       "      <td>w sejmie trwała dziś debata nad sprawozdaniem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wikinews179784</td>\n",
       "      <td>aleksander łukaszenka który za 3 miesiące będz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index                                               word\n",
       "0  wikinews179014  w gdańsku zgodnie już z coroczną czerwcową tra...\n",
       "1  wikinews179354  prezydent usa george bush powiedział że odnowa...\n",
       "2  wikinews179650  mamy najgorsze przedmieścia w europie nie woln...\n",
       "3  wikinews179740  w sejmie trwała dziś debata nad sprawozdaniem ...\n",
       "4  wikinews179784  aleksander łukaszenka który za 3 miesiące będz..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_calc_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileId</th>\n",
       "      <th>ASROutput</th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikinews179014</td>\n",
       "      <td>w gdańsku zgodnie już z coroczną czerwcową tra...</td>\n",
       "      <td>wikinews179014</td>\n",
       "      <td>w gdańsku zgodnie już z coroczną czerwcową tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wikinews179354</td>\n",
       "      <td>prezydent usa george bush powiedział że odnowa...</td>\n",
       "      <td>wikinews179354</td>\n",
       "      <td>prezydent usa george bush powiedział że odnowa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wikinews179650</td>\n",
       "      <td>mamy najgorsze przedmieścia w europie nie woln...</td>\n",
       "      <td>wikinews179650</td>\n",
       "      <td>mamy najgorsze przedmieścia w europie nie woln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikinews179740</td>\n",
       "      <td>w sejmie trwała dziś debata nad sprawozdaniem ...</td>\n",
       "      <td>wikinews179740</td>\n",
       "      <td>w sejmie trwała dziś debata nad sprawozdaniem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wikinews179784</td>\n",
       "      <td>aleksander łukaszenka który za 3 miesiące będz...</td>\n",
       "      <td>wikinews179784</td>\n",
       "      <td>aleksander łukaszenka który za 3 miesiące będz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           FileId                                          ASROutput  \\\n",
       "0  wikinews179014  w gdańsku zgodnie już z coroczną czerwcową tra...   \n",
       "1  wikinews179354  prezydent usa george bush powiedział że odnowa...   \n",
       "2  wikinews179650  mamy najgorsze przedmieścia w europie nie woln...   \n",
       "3  wikinews179740  w sejmie trwała dziś debata nad sprawozdaniem ...   \n",
       "4  wikinews179784  aleksander łukaszenka który za 3 miesiące będz...   \n",
       "\n",
       "            index                                               word  \n",
       "0  wikinews179014  w gdańsku zgodnie już z coroczną czerwcową tra...  \n",
       "1  wikinews179354  prezydent usa george bush powiedział że odnowa...  \n",
       "2  wikinews179650  mamy najgorsze przedmieścia w europie nie woln...  \n",
       "3  wikinews179740  w sejmie trwała dziś debata nad sprawozdaniem ...  \n",
       "4  wikinews179784  aleksander łukaszenka który za 3 miesiące będz...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging for comparison\n",
    "data_test_merged = data_test_clean.merge(\n",
    "    data_test_calc_joined, left_on=\"FileId\", right_on=\"index\"\n",
    ")\n",
    "data_test_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same records:  200\n",
      "Error records:  0\n"
     ]
    }
   ],
   "source": [
    "# fixing errors (mainly spaces at the end)\n",
    "data_test_merged[\"compare\"] = data_test_merged[\"ASROutput\"] == data_test_merged[\"word\"]\n",
    "data_test_merged.loc[\n",
    "    data_test_merged[\"compare\"] == False, \"word\"\n",
    "] = data_test_merged.loc[data_test_merged[\"compare\"] == False, \"word\"].str.strip()\n",
    "data_test_merged[\"compare\"] = data_test_merged[\"ASROutput\"] == data_test_merged[\"word\"]\n",
    "data_test_merged.loc[\n",
    "    data_test_merged[\"compare\"] == False, \"ASROutput\"\n",
    "] = data_test_merged.loc[data_test_merged[\"compare\"] == False, \"ASROutput\"].str.strip()\n",
    "data_test_merged[\"compare\"] = data_test_merged[\"ASROutput\"] == data_test_merged[\"word\"]\n",
    "print(\"Same records: \", data_test_merged[\"compare\"].sum())\n",
    "print(\"Error records: \", data_test_merged.shape[0] - data_test_merged[\"compare\"].sum())\n",
    "data_test_merged.to_csv(\"temp.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1eea36f549d596e1ba6d357da17c58a2c496985ce50cff93b35e7c83413effd0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env_for_ml_st': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
